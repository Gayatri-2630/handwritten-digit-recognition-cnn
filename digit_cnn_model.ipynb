{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "OxCpMTxjx1lA",
        "outputId": "e9b6ea19-6bd0-425a-fb17-442b2aa9735a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model...\n",
            "\n",
            "Epoch 1/3\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 111ms/step - accuracy: 0.8388 - loss: 0.5394 - val_accuracy: 0.9825 - val_loss: 0.0609\n",
            "Epoch 2/3\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 105ms/step - accuracy: 0.9755 - loss: 0.0816 - val_accuracy: 0.9885 - val_loss: 0.0413\n",
            "Epoch 3/3\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 105ms/step - accuracy: 0.9830 - loss: 0.0552 - val_accuracy: 0.9893 - val_loss: 0.0403\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9843 - loss: 0.0447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 98.79%\n",
            "\n",
            "Model saved as 'digit_cnn_model.h5'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
            "\n",
            "Predicted Digit: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "\n",
        "# --------------------------\n",
        "# STEP 1: LOAD + PREPROCESS DATA\n",
        "# --------------------------\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# --------------------------\n",
        "# STEP 2: BUILD THE CNN MODEL\n",
        "# --------------------------\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.25),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# --------------------------\n",
        "# STEP 3: TRAIN THE MODEL\n",
        "# --------------------------\n",
        "print(\"\\nTraining model...\\n\")\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=128, validation_split=0.1)\n",
        "\n",
        "# --------------------------\n",
        "# STEP 4: EVALUATE\n",
        "# --------------------------\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(f\"\\nTest Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# Save model\n",
        "model.save(\"digit_cnn_model.h5\")\n",
        "print(\"\\nModel saved as 'digit_cnn_model.h5'\")\n",
        "\n",
        "# --------------------------\n",
        "# STEP 5: PREDICT CUSTOM IMAGE (AUTO-PROCESSING)\n",
        "# --------------------------\n",
        "def predict_digit(img_path):\n",
        "    # Load image\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image: {img_path}\")\n",
        "        return\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Threshold using Otsu’s method (auto binarization)\n",
        "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Find contours (assuming the largest is the digit)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if len(contours) == 0:\n",
        "        print(\"No digit found in image.\")\n",
        "        return\n",
        "\n",
        "    # Get bounding box of largest contour\n",
        "    contour = max(contours, key=cv2.contourArea)\n",
        "    x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "    digit_roi = thresh[y:y+h, x:x+w]\n",
        "\n",
        "    # Resize ROI to 18x18 and pad to 28x28\n",
        "    resized = cv2.resize(digit_roi, (18, 18), interpolation=cv2.INTER_AREA)\n",
        "    padded = np.pad(resized, ((5,5),(5,5)), \"constant\", constant_values=0)\n",
        "\n",
        "    # Normalize\n",
        "    norm = padded.astype(\"float32\") / 255.0\n",
        "    norm = norm.reshape(1, 28, 28, 1)\n",
        "\n",
        "    # Load model and predict\n",
        "    model = load_model(\"digit_cnn_model.h5\")\n",
        "    pred = model.predict(norm)\n",
        "    digit = np.argmax(pred)\n",
        "\n",
        "    print(f\"\\nPredicted Digit: {digit}\")\n",
        "    plt.imshow(padded, cmap='gray')\n",
        "    plt.title(f\"Predicted: {digit}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# --------------------------\n",
        "# STEP 6: TO USE ON YOUR IMAGE:\n",
        "# --------------------------\n",
        "# Example:\n",
        "predict_digit(\"digi.png\")"
      ]
    }
  ]
}